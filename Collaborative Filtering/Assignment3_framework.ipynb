{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install and load necesary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please don't change this cell\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np  \n",
    "\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0      196      242       3  881250949\n",
       "1      186      302       3  891717742\n",
       "2       22      377       1  878887116\n",
       "3      244       51       2  880606923\n",
       "4      166      346       1  886397596"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Please don't change this cell\n",
    "df = pd.read_csv('ml-100k/u.data', names=['user_id', 'item_id', 'rating', 'timestamp'], sep='\\t')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split dataset\n",
    "## Random Train and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943 users\n",
      "1682 items\n",
      "Construct the rating matrix based on train_df:\n",
      "     0     1     2     3     4     5     6     7     8     9     ...  1672  \\\n",
      "0     0.0   3.0   4.0   3.0   3.0   5.0   4.0   1.0   5.0   3.0  ...   0.0   \n",
      "1     4.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   2.0  ...   0.0   \n",
      "2     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "3     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "4     4.0   3.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "..    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
      "938   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   5.0   0.0  ...   0.0   \n",
      "939   0.0   0.0   0.0   2.0   0.0   0.0   4.0   5.0   3.0   0.0  ...   0.0   \n",
      "940   5.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "941   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "942   0.0   5.0   0.0   0.0   0.0   0.0   0.0   0.0   3.0   0.0  ...   0.0   \n",
      "\n",
      "     1673  1674  1675  1676  1677  1678  1679  1680  1681  \n",
      "0     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "1     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "2     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "3     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "4     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "..    ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
      "938   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "939   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "940   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "941   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "942   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "\n",
      "[943 rows x 1682 columns]\n",
      "Construct the rating matrix based on test_df:\n",
      "     0     1     2     3     4     5     6     7     8     9     ...  1672  \\\n",
      "0     5.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "1     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "2     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "3     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "4     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "..    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
      "938   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "939   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "940   0.0   0.0   0.0   0.0   0.0   0.0   4.0   0.0   0.0   0.0  ...   0.0   \n",
      "941   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "942   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "\n",
      "     1673  1674  1675  1676  1677  1678  1679  1680  1681  \n",
      "0     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "1     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "2     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "3     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "4     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "..    ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
      "938   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "939   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "940   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "941   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "942   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "\n",
      "[943 rows x 1682 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "n_users = df.user_id.unique().shape[0]\n",
    "n_items = df.item_id.unique().shape[0]\n",
    "print(str(n_users) + ' users')\n",
    "print(str(n_items) + ' items')\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state = 10)\n",
    "train_df, test_df\n",
    "\n",
    "# Training Dataset\n",
    "train_ds = np.zeros((n_users, n_items))\n",
    "for row in train_df.itertuples():\n",
    "    train_ds[row[1]-1, row[2]-1] = row[3]\n",
    "train_ds = pd.DataFrame(train_ds)\n",
    "\n",
    "# Testing Dataset\n",
    "test_ds = np.zeros((n_users, n_items))\n",
    "for row in test_df.itertuples():\n",
    "    test_ds[row[1]-1, row[2]-1] = row[3]\n",
    "test_ds = pd.DataFrame(test_ds)\n",
    "\n",
    "print(\"Construct the rating matrix based on train_df:\")\n",
    "print(train_ds)\n",
    "\n",
    "print(\"Construct the rating matrix based on test_df:\")\n",
    "print(test_ds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please don't change this cell\n",
    "EPSILON = 1e-9\n",
    "\n",
    "def evaluate(test_ds, predicted_ds):\n",
    "    '''\n",
    "    Function for evaluating on MAE and RMSE\n",
    "    '''\n",
    "    # MAE\n",
    "    mask_test_ds = test_ds > 0\n",
    "    MAE = np.sum(np.abs(test_ds[mask_test_ds] - predicted_ds[mask_test_ds])) / np.sum(mask_test_ds.astype(np.float32))\n",
    "\n",
    "    # RMSE\n",
    "    RMSE = np.sqrt(np.sum(np.square(test_ds[mask_test_ds] - predicted_ds[mask_test_ds])) / np.sum(mask_test_ds.astype(np.float32)))\n",
    "\n",
    "    return MAE, RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get User Similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.15598017,  0.01121976, ...,  0.08421613,\n",
       "        -0.02888167, -0.05569836],\n",
       "       [ 0.15598017,  1.        ,  0.04418078, ..., -0.01518162,\n",
       "         0.02540037,  0.1535033 ],\n",
       "       [ 0.01121976,  0.04418078,  1.        , ...,  0.0566994 ,\n",
       "        -0.07264523,  0.03333333],\n",
       "       ...,\n",
       "       [ 0.08421613, -0.01518162,  0.0566994 , ...,  0.56666667,\n",
       "        -0.06666667,  0.00212055],\n",
       "       [-0.02888167,  0.02540037, -0.07264523, ..., -0.06666667,\n",
       "         1.        ,  0.17427709],\n",
       "       [-0.05569836,  0.1535033 ,  0.03333333, ...,  0.00212055,\n",
       "         0.17427709,  1.        ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get user similarities\n",
    "GAMMA = 30\n",
    "EPSILON = 1e-9\n",
    "\n",
    "np_user_pearson_corr = np.zeros((n_users, n_users))\n",
    "\n",
    "for i, user_i_vec in enumerate(train_ds.values):\n",
    "    for j, user_j_vec in enumerate(train_ds.values):\n",
    "\n",
    "        # ratings corated by the current pair of users\n",
    "        mask_i = user_i_vec > 0\n",
    "        mask_j = user_j_vec > 0\n",
    "\n",
    "        # corrated item index, skip if there are no corrated ratings\n",
    "        corrated_index = np.intersect1d(np.where(mask_i), np.where(mask_j))\n",
    "        if len(corrated_index) == 0:\n",
    "            continue\n",
    "\n",
    "        # average value of user_i_vec and user_j_vec\n",
    "        mean_user_i = np.sum(user_i_vec) / (np.sum(np.clip(user_i_vec, 0, 1)) + EPSILON)\n",
    "        mean_user_j = np.sum(user_j_vec) / (np.sum(np.clip(user_j_vec, 0, 1)) + EPSILON)\n",
    "\n",
    "        # compute pearson corr\n",
    "        user_i_sub_mean = user_i_vec[corrated_index] - mean_user_i\n",
    "        user_j_sub_mean = user_j_vec[corrated_index] - mean_user_j\n",
    "\n",
    "        r_ui_sub_r_i_sq = np.square(user_i_sub_mean)\n",
    "        r_uj_sub_r_j_sq = np.square(user_j_sub_mean)\n",
    "\n",
    "        r_ui_sum_sqrt = np.sqrt(np.sum(r_ui_sub_r_i_sq))\n",
    "        r_uj_sum_sqrt = np.sqrt(np.sum(r_uj_sub_r_j_sq))\n",
    "\n",
    "        sim = np.sum(user_i_sub_mean * user_j_sub_mean) / (r_ui_sum_sqrt * r_uj_sum_sqrt + EPSILON)\n",
    "\n",
    "        # significance weighting\n",
    "        weighted_sim = (min(len(corrated_index), GAMMA) / GAMMA) * sim\n",
    "\n",
    "        np_user_pearson_corr[i][j] = weighted_sim\n",
    "\n",
    "np_user_pearson_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deviation_j_i(item_j,item_i,u_prime,common_users):\n",
    "    \n",
    "    # co-rated index of users who have rated both item i and j (u ∈ S_sub_j,i(χ))\n",
    "    corrated_index = common_users\n",
    "    \n",
    "    #return a deviation of 0 if no users are present that rated both items\n",
    "    if len(corrated_index) == 0:\n",
    "            return 0\n",
    "       \n",
    "    #to hold: card((Sj,i(χ)))\n",
    "    card_SX = len(corrated_index) + EPSILON\n",
    "    \n",
    "    #to hold: sum[(uj - ui) / card(S_sub_j,i(χ))]\n",
    "    sum_uj_minus_ui_over_card_Sx = 0\n",
    "    \n",
    "    #to hold: sum u∈Sj,i(χ)[((uj − ui) · exp(sim(u, u′)))]\n",
    "    sum_uj_minus_ui_into_exp_sim=0\n",
    "    \n",
    "    #to hold: sum u∈Sj,i(χ)[exp(sim(u, u′)) · card(Sj,i(χ))]\n",
    "    sum_exp_sim_card=0\n",
    "    \n",
    "    #iterate through corated users (u∈Sj,i(χ))\n",
    "    for user_index in corrated_index:\n",
    "        #skip same user\n",
    "        if(user_index==u_prime):\n",
    "            continue\n",
    "            \n",
    "        #to hold uj - ui\n",
    "        uj_minus_ui = np_train_ds[user_index][item_j]-np_train_ds[user_index][item_i]\n",
    "        \n",
    "        #to hold: exp(sim(u, u′))\n",
    "        exp_sim = math.pow(2,np_user_pearson_corr[user_index,u_prime])\n",
    "        \n",
    "        #calc sum[(uj - ui) / card(S_sub_j,i(χ))]\n",
    "        sum_uj_minus_ui_over_card_Sx += uj_minus_ui/card_SX\n",
    "        \n",
    "        #calc sum u∈Sj,i(χ)[((uj − ui) · exp(sim(u, u′)))]\n",
    "        sum_uj_minus_ui_into_exp_sim += uj_minus_ui*exp_sim\n",
    "        \n",
    "        #calc sum u∈Sj,i(χ)[exp(sim(u, u′)) · card(Sj,i(χ))]\n",
    "        sum_exp_sim_card += exp_sim * card_SX\n",
    "    \n",
    "#   LHS of plus sign in dev(j,i) equation\n",
    "    dev_lhs = LAMDA * sum_uj_minus_ui_over_card_Sx\n",
    "        \n",
    "#   RHS of plus sign in dev(j,i) equation\n",
    "    dev_rhs = (1-LAMDA) * (sum_uj_minus_ui_into_exp_sim/sum_exp_sim_card)\n",
    "    \n",
    "    #return final deviation of item i and j\n",
    "    dev = dev_lhs+dev_rhs    \n",
    "    return dev      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get co-rated users for each item pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this cell took -  1 min 30 secs to run\n",
    "#this cell calculates all users who have rated all pairs of items i and j and stores them in a dictionary to improve efficiency\n",
    "#the dictionary will hold a key which is a pair of items, eg: co_rated_users_dict[(item_i,item_j)] would return a np array of users who has rated both items\n",
    "\n",
    "#convert train_ds into numpy array for faster calculations\n",
    "np_train_ds = train_ds.values\n",
    "\n",
    "#keep dictionary to store co-rated user of items i and j\n",
    "co_rated_users_dict = {}\n",
    "\n",
    "# Iterate over all pairs of items (i, j)\n",
    "for i in range(n_items):   \n",
    "    # Get the indices of users who have rated item i\n",
    "    mask_i = np.where(np_train_ds[:, i] > 0)[0]\n",
    "    \n",
    "    for j in range(n_items):\n",
    "        if(j==i):\n",
    "            continue\n",
    "        # Get the indices of users who have rated item j\n",
    "        mask_j = np.where(np_train_ds[:, j] > 0)[0]\n",
    "\n",
    "        # Find the common users who have rated both item i and j\n",
    "        corrated_index = np.intersect1d(mask_i, mask_j)\n",
    "\n",
    "\n",
    "        # Store the common users in the dictionary\n",
    "        co_rated_users_dict[(i, j)] = corrated_index\n",
    "    #uncomment print to track i value, once i reaches 1681 run ends\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this cell took -  15 mins to run\n",
    "#predict ratings personalised weighted slope one method\n",
    "\n",
    "np_predictions = np.zeros((n_users, n_items))\n",
    "\n",
    "K = 100\n",
    "EPSILON = 1e-9\n",
    "LAMDA = 0.8\n",
    "\n",
    "for (u_prime, j), rating in np.ndenumerate(test_ds.values):\n",
    "    if rating <= 0:\n",
    "        continue\n",
    "    \n",
    "    prediction = 0\n",
    "    sum_numerator = 0\n",
    "    sum_denominator = EPSILON\n",
    "    \n",
    "    #skip if user has already rated item j\n",
    "    if(np_train_ds[u_prime][j]!=0):\n",
    "        continue\n",
    "    \n",
    "    #calc Si∈S(u′)−{j}[((devj,i + u′i)cj,i)] / Si∈S(u′)−{j}[C_ji] \n",
    "    for i in range(n_items):\n",
    "        #skip same item\n",
    "        if(j==i):\n",
    "            continue\n",
    "\n",
    "        # co-rated index of users who have rated both item i and j\n",
    "        corrated_index = co_rated_users_dict[(i, j)]\n",
    "        #C_sub_ji is all co-rated users of items i,j\n",
    "        c_j_i = len(corrated_index) + EPSILON\n",
    "#         print(c_j_i)\n",
    "        \n",
    "        #get deviation of item i with respect to item j\n",
    "        dev_j_i = deviation_j_i(j,i,u_prime,corrated_index)\n",
    "        \n",
    "        #get rating of item i by u_prime\n",
    "        u_prime_i_rating = np_train_ds[u_prime][i]\n",
    "        \n",
    "        sum_numerator += (dev_j_i+u_prime_i_rating)*c_j_i\n",
    "#         sum_denominator += c_j_i\n",
    "        sum_denominator += 1\n",
    "        \n",
    "            \n",
    "    prediction = sum_numerator/sum_denominator\n",
    "    np_predictions[u_prime,j] = np.clip(prediction, 0, 5)\n",
    "    \n",
    "    #uncomment print(u_prime), when u_prime reaches 942 run ends\n",
    "#     print(u_prime)\n",
    "    \n",
    "np_predictions       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAE and RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAE and RMSE results\n",
    "MAE, RMSE = evaluate(test_ds, pd.DataFrame(np_predictions))\n",
    "\n",
    "MAE = np.mean(MAE)\n",
    "RMSE = np.mean(RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================== The MAE and RMSE of Your Implementation =====================\n",
      "MAE: 1.838357066554049, RMSE: 2.0683103676073196\n"
     ]
    }
   ],
   "source": [
    "# Please don't change this cell\n",
    "\n",
    "print(\"===================== The MAE and RMSE of Your Implementation =====================\")\n",
    "print(\"MAE: {}, RMSE: {}\" .format(MAE, RMSE))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
